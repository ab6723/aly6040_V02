---
title: "Module 2 Final Project â€” Milestone 1: EDA"
author: "Abby Bridgers and Justin Ehringhaus"
date: "July 24, 2022"
output:
  html_document: default
bibliography: "references.bib"
nocite: '@*'
---
 
---

```{r setup, include=FALSE}
# repo: https://github.com/ab6723/aly6040_V02
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(pacman)
p_load(tidyverse)  # usual suite of packages
p_load(ggthemes)   # extra themes
p_load(hrbrthemes)
p_load(skimr)      # alternative to summary(), skims dataset: skim()
p_load(VIM)        # visualization of missing values: aggr()
p_load(corrplot)   # visualization of a correlation matrix: corrplot()
```

---

## Data Preparation

```{r message=FALSE, warning=FALSE}
wvs <- read_csv("../WVS_Cross-National_Wave_7_csv_v4_0.csv")
head(wvs)[,1:5]
```

```{r}
wvs_subset <- 
  wvs %>% 
  select(
    Country = B_COUNTRY_ALPHA,
    Longitude = O1_LONGITUDE,
    Latitude = O2_LATITUDE,
    Age = Q262,
    Income.Group = Q288,
    Ethnic.Group = Q290, # see WVS_codebook.pdf for Q290 coding info
    Immigrant = Q263,
    Religion = Q289,
    Marital.Status = Q273,
    Education = Q275,
    Number.Children = Q274,
    Happiness = Q46,
    Health = Q47,
    votes.locally = Q221,
    votes.nationally = Q222,
    cheating.taxes = Q180,
    gov.video.surveillance = Q196,
    gov.email.monitoring = Q197,
    gov.collecting.info = Q198,
    terrorism = Q192,
    death.penalty = Q195,
    suicide = Q187,
    beating.wife = Q189,
    beating.children = Q190,
    homosexuality = Q182,
    prostitution = Q183,
    abortion = Q184,
    divorce = Q185,
    casual.sex = Q193,
    sex.before.marriage = Q186,
    )
```

## Analysis & Interpretation

```{r}
skim(wvs_subset)
```

...Write about observations of the skim here...

```{r}
# getting rid of continuous data
# only want to count unique values and counts for categorical data
wvs_subset_categorical <- 
  wvs_subset %>% 
  select(-Longitude,
         -Latitude)

lapply(wvs_subset_categorical, table)
```

...Write about observations of counts of unique values per variable here...

```{r}
# getting rid of nominal data / continuous data
# only want to assess correlations between ordinal data
wvs_subset_ordinal <- 
  wvs_subset %>% 
  select(-Longitude,
         -Latitude,
         -Country, 
         -Ethnic.Group, 
         -Religion)

cor <- cor(wvs_subset_ordinal, use = "pairwise.complete.obs")
corrplot(cor, 
         method = "circle", 
         insig = "blank", 
         diag = FALSE,
         tl.cex = 0.7) %>% 
    corrRect(name = c('Age', 
                      'votes.locally', 
                      'cheating.taxes', 
                      'homosexuality', 
                      'sex.before.marriage'))
```

...Write about observations of correlation matrix here...

```{r}
# Testing this... not working, but just an idea for long/lat values
p_load(maps)
map("world")
points(wvs_subset$Latitude, wvs_subset$Longitude, col = "red", pch = ".", cex = 2)
```

```{r}
Religion.names <- c('No Religion', 'Roman Catholic', 'Protestant', 'Orthodox',
                    'Jew', 'Muslim', 'Hindu', 'Buddhist', 'Other Christian', 'Other', 'NA')

wvs_subset %>% 
  ggplot +
  aes(x = factor(Number.Children), fill = factor(Religion)) +
  geom_bar(position = "fill") +
  scale_fill_discrete(name = "Religious Denomination",
                      labels = Religion.names) +
  xlab("Number of Children") +
  ylab("Proportion") +
  theme_tufte()
```

- For almost all counts of children, Muslims proportionally dominate other religious denominations.
- Those without a religion generally have fewer children.
- It appears outliers are present, such as families with 12+ children, this can be checked by running:

```{r}
table(wvs_subset$Number.Children, wvs_subset$Religion)
```

- BUT, this data is accurate, and so it may not be wise to consider this an outlier. The dataset is meant to encapsulate human values, the human experience, and actual occurences. So deleting data just because it is outside our view of "what is normal" would, in contrast, skew the data.

## Analysis & Interpretation - Subset 2

```{r}
colnames(wvs_subset)
wvs_subset2 <- wvs %>% 
  select(Country = B_COUNTRY_ALPHA,
    Longitude = O1_LONGITUDE,
    Latitude = O2_LATITUDE,
    Settlement.type = H_SETTLEMENT,
    Country.and.year = S025,
    Town.size = G_TOWNSIZE2,
    Age = Q262,
    Income.group = Q288,
    Importance.leisure.time = Q3,
    Importance.work = Q5,
    Happiness = Q46,
    Health = Q47,
    Confidence.elections = Q76,
    Confidence.courts = Q70,
    Confidence.UN = Q83,
    Environment.vs.econgrow = Q111,
    Job.scarcity.prioritize.nonimmigrants = Q34,
    Immigration.in.country.fills.useful.jobs = Q122,
    Immigration.in.country.strengthens.cultural.div = Q123,
    Immigration.in.country.increases.crime.rate = Q124,
    Immigration.in.country.gives.political.asylum = Q125,
    Immigration.in.country.increases.terrorism.risk = Q126,
    Immigration.in.country.helps.poor.people.est.new.lives = Q127,
    Immigration.in.country.increases.unemployment = Q128,
    Immigration.in.country.brings.social.conflict = Q129,
    Immigration.policy.preference = Q130)
```

# Checking out the subset
```{r}
colnames(wvs_subset2)
skim(wvs_subset2)
```

...Initial obs...

# basic barchart
```{r}
ggplot(wvs_subset2, aes(x=Confidence.courts, y=Age)) + 
  geom_bar(stat = "identity")
```

...Obs...

# age hist - adults
```{r}
p <- wvs_subset2 %>%
  filter( Age>17 ) %>%
  ggplot( aes(x=Age)) +
    geom_histogram( binwidth=3, fill="#69b3a2", color="#e9ecef", alpha=0.9) +
    ggtitle("Bin size = 3") +
    theme_ipsum() +
    theme(
      plot.title = element_text(size=15)
    )
p
```

...Obs...

# tables & correlation
```{r}
table(wvs_subset2$Age, wvs_subset2$Immigration.in.country.brings.social.conflict)
prop.table(table(wvs_subset2$Age))

data.frame(colnames(wvs_subset2))
wvs_subset3 <- wvs_subset2[c(-1,-2,-3,-7, -11, -12)]
str(wvs_subset3)
cor(wvs_subset3, use = "complete.obs")
```

...Obs...future questions/analysis based on findings in correlation matrix...

# age overlaid with income in prop bar chart
```{r}
library(ggthemes)
Income.details <- c('Lower Step', 'Second Step', 'Third Step', 'Fourth Step', 'Fifth Step', 'Sixth Step', 'Sixth Step', 'Seventh Step', 'Eigth Step', 'Nineth Step', 'Tenth Step', 'Unknown', 'No Answer', 'Not Asked', 'NA')

wvs_subset2 %>% 
  ggplot +
  aes(x = Age, fill = factor(Income.group)) +
  geom_bar(position = "fill") +
  scale_fill_discrete(name = "Income Group",
                      labels = Income.details) +
  xlab("Age") +
  ylab("Proportion") +
  ggtitle("Income Group Proportion By Age")
  theme_hc()
```

...Obs...mention interest in exploring diverging bar chart...perhaps also likert() function interest...

# Subset combining our variables in anticipation of working from one subset in Module 3 
xx23 <- merge(wvs_subset, wvs_subset2)
str(xx23)
drop <- c("Income.group")
wvs_subset_mod3 = xx23[,!(names(xx23) %in% drop)]
str(wvs_subset_mod3) 

# 49 variables, 325,552 observations in combined dataframe
---

## TASKS

- Calculate appropriate summary statistics - done
- Create appropriate graphs that will give you insights into the data. - done

Include the answers to following questions:

- What did you do with the data in the context of exploration?
We created subsets with our data to explore and analyze from two perspectives. This allowed us to form separate viewpoints and then share knowledge in order to better understand the steps necessary to prepare the data for further analysis. 

- How many entries are in the dataset?
The Wave 7 WVS dataset contains 552 variables and 87,822 rows. We reduced the number of attributes by about 90%, landing on 49 rows of data. 

- Was there missing data? Duplications? How clean was the data?
- Were their outliers or suspicious data?
- What did you do to clean the data?
While there were missing data and and duplications found in our dataset, we elected to refrain from cleaning the data because doing so may unintentionally falsify the results of the WVS survey. In a typical data cleaning process, outliers are removed to concentrate on the central tendency of the data. Missing data is removed and/or standardized for numerical analysis. Since our data is ordinal, and we are interested in including and analyzing the data holistically, we did not feel that it would be appropriate "clean" the data beyond changing column names, selecting attributes of interest, and ensuring that there weren't a prohibitory amount of NA values found in our subsets of interest. 

- What did you find? What intrigued you about the data? Why does that matter?
- What would your proposed next steps be?
- What business questions do you plan to answer with your data mining?